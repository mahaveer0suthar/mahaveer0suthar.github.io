

<!doctype html>
<html lang="en" class="no-js">
  <head>
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-3852793730107162",
        enable_page_level_ads: true
      });
    </script>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Training With Your Own Dataset on Caffe - Mahaveer Senior Deep Learning Engineer</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Mahaveer Senior Deep Learning Engineer">
<meta property="og:title" content="Training With Your Own Dataset on Caffe">


  <link rel="canonical" href="http://localhost:4000/mahaveer0suthar.github.io/project/Training-Your-Own-Data-On-Caffe/">
  <meta property="og:url" content="http://localhost:4000/mahaveer0suthar.github.io/project/Training-Your-Own-Data-On-Caffe/">



  <meta property="og:description" content="Hi, everyone! Welcome back to my Machine Learning page today. I have been playing around with Caffe for a while, and as you already knew, I made a couple of posts on my experience in installing Caffe and making use of its state-of-the-art pre-trained Models for your own Machine Learning projects. Yeah, it’s really great that Caffe came bundled with many cool stuff inside which leaves developers like us nothing to mess with the Networks. But of course, there comes sometime that you want to set up your own Network, using your own dataset for training and evaluating. And it turns out that using all the things which Caffe provides us doesn’t help Caffe look less like a blackbox, and it’s pretty hard to figure things out from the beginning. And that’s why I decided to make this post, to give you a helping hand to literally make use of Caffe.">





  

  



  <meta property="og:image" content="http://localhost:4000/mahaveer0suthar.github.io/images/teaser.jpg">



  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2017-11-09T00:00:00+05:30">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Mahaveer Suthar",
      "url" : "http://localhost:4000/mahaveer0suthar.github.io",
      "sameAs" : null
    }
  </script>



  <meta name="google-site-verification" content="ho8trrB9Qh7KHvxD-AUywATdPAOr6EJQ3pQbX6bfZFA" />




<!-- end SEO -->


<link href="http://localhost:4000/mahaveer0suthar.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Mahaveer Senior Deep Learning Engineer Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/mahaveer0suthar.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">


    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--post">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/mahaveer0suthar.github.io/">Mahaveer Senior Deep Learning Engineer</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/mahaveer0suthar.github.io/about/">About</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://mahaveer0suthar.github.io/portfolio/">Projects</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/mahaveer0suthar.github.io/experience/">Professional Experience</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/mahaveer0suthar.github.io/skills/">Skills & Areas of Interests</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/mahaveer0suthar.github.io/education/">Education</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://mahaveer0suthar.github.io/tutorials/">Tutorials</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>Hi, everyone! Welcome back to my Machine Learning page today. I have been playing around with Caffe for a while, and as you already knew, I made a couple of posts on my experience in installing Caffe and making use of its state-of-the-art pre-trained Models for your own Machine Learning projects. Yeah, it’s really great that Caffe came bundled with many cool stuff inside which leaves developers like us nothing to mess with the Networks. But of course, there comes sometime that you want to set up your own Network, using your own dataset for training and evaluating. And it turns out that using all the things which Caffe provides us doesn’t help Caffe look less like a <em>blackbox</em>, and it’s pretty hard to figure things out from the beginning. And that’s why I decided to make this post, to give you a helping hand to literally make use of Caffe.</p>

<p>Before getting into the details, for ones that missed my old posts on Caffe, you can check it out anytime, through the links below:</p>

<ul>
  <li>
    <p><a href="https://mahaveer0suthar.github.io/project/Installing-Caffe-CPU-Only/" target="_blank">Installing Caffe on Ubuntu (CPU_ONLY)</a></p>
  </li>
  <li>
    <p><a href="https://mahaveer0suthar.github.io/project/Installing-Caffe-Ubuntu/" target="_blank">Installing Caffe on Ubuntu (GPU)</a></p>
  </li>
</ul>

<p>Now, let’s get down to business. In today’s post, I will mainly tell you about two points below:</p>

<ul>
  <li>
    <p>Downloading your own dataset</p>
  </li>
  <li>
    <p>Preparing your data before training</p>
  </li>
  <li>
    <p>Training with your prepared data</p>
  </li>
</ul>

<p>So, I will go straight to each part right below.</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p><strong>1. Downloading your data</strong><br />
I think there’s a lot of ways which everyone of you managed to get your own dataset. If your dataset has been already placed on your hard disk, then you can skip the <strong>Downloading</strong> section and jump right into the <strong>Preparing</strong> section. Here I’m assuming that you do not have any dataset of your own, and you’re intending to use some dataset from free sources like ImageNet or Flickr or Kaggle. Then it’s likely that: you can directly download the dataset (from sources like Kaggle), or you will be provided a text file which contains URLs of all the images (from sources like Flickr or ImageNet). The latter seems to be harder, but don’t worry, it won’t be that hard.</p>

<ul>
  <li>Directly downloading from source:</li>
</ul>

<p>This kind of download is quite easy. Here I will use the <strong>Dogs vs. Cats</strong> dataset from Kaggle for example. You can access the dataset from the Download page: <a href="https://www.kaggle.com/c/dogs-vs-cats">Dogs vs. Cats</a>. All you have to do is just register an account, then you can download the whole dataset. There are two of them, one for training purpose, which was named <em>train</em>, and one for evaluating, which was named <em>test1</em> respectively. I suggest that you should download the training set only. I will explain why when we come to the <strong>Preparing</strong> section. The file size is quite large so it should take a while to finish. And that’s it. You have the dataset stored on your hard disk!</p>

<ul>
  <li>Downloading from URLs</li>
</ul>

<p>As you could see above, it’s great if every dataset was zipped and provided directly to developers. But in fact, due to the copyright of the images (as well as other data types), providing data that way isn’t simple, especially when we talk about an extremely large dataset like ImageNet. So data providers have another way, which is providing you the URLs only, and you will have to access to the image hosts yourself to download the data. I will use a very famous site for example, which is ImageNet, the site which holds the annual ILSVRC. You can read more about ILSVRC <a href="http://www.image-net.org/challenges/LSVRC/" target="_blank">here</a>.</p>

<p>First, let’s go to the ImageNet’s URLs download page: <a href="http://image-net.org/download-imageurls" target="_blank">Download Image URLs</a>. All you need to know to get the URLs is something called <strong>WordNet ID</strong> (or <strong>wnid</strong>). You can read more about ImageNet’s dataset and WordNet to grab some more details because this post will be too long if I explain it here. To make it simple right now, ImageNet uses WordNet’s synset, such as <em>n02084071</em>, <em>n02121620</em> which represents <em>dogs</em> and <em>cats</em> respectively, to name its classes. To find out what the synset of a particular noun, just access <a href="http://www.image-net.org/synset?wnid" target="_blank">Noun to Synset</a>, then search for any noun you want, then you will see the corresponding synset.</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds2 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="2275566366" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>Once you knew the synset, you can download the URLs by going to this page:<br />
http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=[wnid], which <em>[wnid]</em> is the synset of the object you want to download data for. For example, let’s use two synsets above, to download the URLs of the Dogs and Cats images of ImageNet:</p>

<p>Dogs: http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02084071</p>

<p>Cats: http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02121620</p>

<p>If you access the links above, you will see something like this:</p>

<p><img src="/images/projects/training-your-own-data-on-caffe/urls.png" alt="urls" /></p>

<p>So, the next thing to do is just simple, you have to copy those URLs and paste somewhere, let’s say a text file or something. With ones who are familiar with Linux commands, you can see that we can use <em>wget</em> to grab all the images with ease. But there’s some problem here: using <em>wget</em> is hard to rename the images as <em>wget</em> will use the name right in each URL to name each image. Training your own data with CNN on Caffe may not require any naming rules, but if you have intention to use your own data in other places, for example, the state-of-the-art Faster R-CNN, then the naming convention does matter! And as far as I know, we can manually rename all the images while downloading using <em>wget</em>, but it requires some experience in Linux commands, and to be honest, I tried and failed. But don’t worry, I found the solution for that!</p>

<p>You know that Caffe provides us so many useful tools, to help us do all the heavy things so that we can use all the pre-trained Models without worrying about the data preparation, which means that, if you want to play with MNIST, Caffe provides you the script to download MNIST, if you want to play with CIFAR-10, Caffe got a script to download CIFAR-10 too. So, we can make use of the tools Caffe provides, and modify a little to make it work with our data. Not so bad, right?</p>

<p>All you have to do, is to make use of the tool which Caffe uses to download Flickr’s images for fine-tuning (I will tell you about fine-tuning in the second part, so don’t care about that term). Open your terminal, and type the commands below (make sure that you are in the root folder of Caffe):</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd </span>data
<span class="nb">mkdir </span>DogsCats

<span class="nb">cd</span> ../examples
<span class="nb">mkdir </span>DogsCats
<span class="nb">sudo cp </span>finetune_flickr_style/<span class="k">*</span> DogsCats/<span class="k">*</span></code></pre></figure>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>What we just did, is to create the neccessary folders for storing the script (<em>./examples/DogsCats</em>) and the images (*./data/DogsCats), then we copied the script to download Flickr’s images to our new folder. Obviously, we have to make some changes in order to make it work properly, just some minor changes.</p>

<p>First, let’s go to <em>./examples/DogsCats</em> folder, unzip the <em>flickr_style.csv.gz</em> to get a CSV file named <em>flickr_style.csv</em>. Open it up, take a look at the file. There are five columns but just three of them are actually used: <em>image_url</em>, <em>label</em> and <em>_split</em>. The <em>image_url</em> column stores all the URLs to all the images, the <em>label</em> column stores the label values, and the <em>_split</em> column tells whether each image is used for training or evaluating purpose.</p>

<p>As I mentioned earlier, we are not only downloading the images, but also renaming it, so we will use an additional column to store the name associating with each image URL, which I chose column <em>A</em> for that task. Before making any changes, let’s deleting all the records, except the first row. Then, let’s name cell A1 <em>image_name</em>. Next, in the <em>image_url</em> column, paste all the URLs of each class. Note that we won’t paste all the URLs of all classes at once, since we have to labeling them. After pasting all the URLs of one class, let’s say the Dogs class with <em>n02084071</em> synset, we will fill the <em>image_name</em> column. Start from cell A2, let’s fill that it will <em>n02084071_0</em> then drag until you see the last URL in <em>image_url</em> column. Don’t forget to add the <em>.jpg</em> extension when you finish (just use the CONCATENATE function).</p>

<p>Next, we will label the images we have just added URLs for. In the <em>label</em> column, let’s fill with <em>0</em> until the last row containing URL. Since all URLs we pasted belong to Dogs, so they will have the same label. And lastly, let’s fill in the <em>_split</em> column. In case of the Dogs’ images, we have 1603 images in total, so let’s fill <em>train</em> for the first 1200 images and <em>test</em> for the rest (here the train:test ratio I chose is 0.75:0.25). After all, your CSV should look similar to this:</p>

<p><img src="/images/projects/training-your-own-data-on-caffe/csv.png" alt="csv" /></p>

<p>And we can continue with other classes’ images, don’t forget to increase the value of <em>label</em> column each time you add another class’s URLs.</p>

<p>So, we have done with the CSV file, let’s go ahead and modify the Python script (make sure that you are in the root folder of Caffe):</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd </span>examples/DogsCats
<span class="nb">sudo </span>vim assemble_data.py</code></pre></figure>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>First, let’s replace all the phrase <em>data/finetune_flickr_style</em> with *data/DogsCats. That value tells where to store the downloaded images, so we have to point to our new created folder. Next, make some changes like below:</p>

<figure class="highlight"><pre><code class="language-vim" data-lang="vim"># Line <span class="m">63</span>
df <span class="p">=</span> pd<span class="p">.</span>read_csv<span class="p">(</span>csv_filename<span class="p">,</span> index_col<span class="p">=</span>None<span class="p">,</span> compression<span class="p">=</span><span class="s1">'gzip'</span><span class="p">)</span>

# Line <span class="m">77</span>
os<span class="p">.</span>path<span class="p">.</span><span class="k">join</span><span class="p">(</span>images_dirname<span class="p">,</span> value<span class="p">)</span> <span class="k">for</span> value <span class="k">in</span> df<span class="p">[</span><span class="s1">'image_name'</span><span class="p">]</span></code></pre></figure>

<p>That’s it. And now we are ready to download the images, and have them renamed the way we wanted:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">python assemble_data.py</code></pre></figure>

<p>It will take a while for the script to run. Note that many of the URLs are inaccessible at the time of writing, since many of them were added quite so long ago. So if you notice that the number of downloaded images is not equal to the number of URLs, don’t be confused.</p>

<p>As soon as the script finished running, then your images are all stored on your drive. So now your dataset is ready for the next stage!</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds2 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="2275566366" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p><strong>2. Preparing the data before training</strong><br />
So we just managed to have the desired dataset stored on your hard disk. And believe me or not, we have just completed the most time-consuming task! Before we can train our Network using the data we have just downloaded, there’s some things we need to do. First, we need to convert the downloaded images into the format that the Networks can read. In fact, the Networks in Caffe accepts not just one kind of input data. As far as I know, there are three different ways to prepare our images so that the Networks can read them, and I’m gonna tell you about two of them: normal format and LMDB format. And second, we need to provide one special image called <em>the mean image</em>. Okay, let’s get into each of them.</p>

<ul>
  <li>Creating the train.txt and test.txt files</li>
</ul>

<p>Let’s first talk about the data conversion. As I said above, we have two choices. You can choose whether to use the normal format (leave the images untouched after downloaded), or to convert them to LMDB format. In both cases, you have to create two files called <em>train.txt</em> and <em>text.txt</em>. What the two files do is to tell our Network where to look for each image and its corresponding class. To understand better, let’s go and create them.</p>

<p>I’m gonna use the <em>Dogs vs Cats</em> dataset which we downloaded from Kaggle (because we haven’t touched it yet, have we?). Let’s create two similar folders just like we did above with ImageNet’s images, one for storing the images, and one for storing the necessary scripts:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd </span>examples
<span class="nb">mkdir </span>DogsCatsKaggle
<span class="nb">cd</span> ../data
<span class="nb">mkdir </span>DogsCatsKaggle</code></pre></figure>

<p>Then, let’s place the zip file which we downloaded from Kaggle into <em>./data/DogsCatsKaggle</em> folder and upzip it. After unzipped, all of the images will be stored into the subfolder called <em>train</em>. Next, we’re gonna create the <em>train.txt</em> and <em>test.txt</em> files. Let’s go into the <em>./examples/DogsCatsKaggle</em> folder and create a Python file, name it <em>create_kaggle_txt.py</em> and fill the codes below:</p>

<figure class="highlight"><pre><code class="language-vim" data-lang="vim">import numpy <span class="k">as</span> np
import os
 
CURRENT_DIR <span class="p">=</span> os<span class="p">.</span>path<span class="p">.</span>abspath<span class="p">(</span>os<span class="p">.</span>path<span class="p">.</span>dirname<span class="p">(</span>__file__<span class="p">))</span>
DATA_DIR <span class="p">=</span> os<span class="p">.</span>path<span class="p">.</span>abspath<span class="p">(</span>os<span class="p">.</span>path<span class="p">.</span><span class="k">join</span><span class="p">(</span>CURRENT_DIR<span class="p">,</span> <span class="s1">'../../data/DogsCatsKaggle/train'</span><span class="p">))</span>
TXT_DIR <span class="p">=</span> os<span class="p">.</span>path<span class="p">.</span>abspath<span class="p">(</span>os<span class="p">.</span>path<span class="p">.</span><span class="k">join</span><span class="p">(</span>CURRENT_DIR<span class="p">,</span> <span class="s1">'../../data/DogsCatsKaggle'</span><span class="p">))</span>
 
dog_images <span class="p">=</span> <span class="p">[</span>image <span class="k">for</span> image <span class="k">in</span> os<span class="p">.</span>listdir<span class="p">(</span>DATA_DIR<span class="p">)</span> <span class="k">if</span> <span class="s1">'dog'</span> <span class="k">in</span> image<span class="p">]</span>
cat_images <span class="p">=</span> <span class="p">[</span>image <span class="k">for</span> image <span class="k">in</span> os<span class="p">.</span>listdir<span class="p">(</span>DATA_DIR<span class="p">)</span> <span class="k">if</span> <span class="s1">'cat'</span> <span class="k">in</span> image<span class="p">]</span>
 
dog_train <span class="p">=</span> dog_images<span class="p">[:</span>int<span class="p">(</span>len<span class="p">(</span>dog_images<span class="p">)</span>*<span class="m">0</span><span class="p">.</span><span class="m">7</span><span class="p">)]</span>
dog_test <span class="p">=</span> dog_images<span class="p">[</span>int<span class="p">(</span>len<span class="p">(</span>dog_images<span class="p">)</span>*<span class="m">0</span><span class="p">.</span><span class="m">7</span><span class="p">):]</span>
 
cat_train <span class="p">=</span> cat_images<span class="p">[:</span>int<span class="p">(</span>len<span class="p">(</span>cat_images<span class="p">)</span>*<span class="m">0</span><span class="p">.</span><span class="m">7</span><span class="p">)]</span>
cat_test <span class="p">=</span> cat_images<span class="p">[</span>int<span class="p">(</span>len<span class="p">(</span>cat_images<span class="p">)</span>*<span class="m">0</span><span class="p">.</span><span class="m">7</span><span class="p">):]</span>
 
with open<span class="p">(</span><span class="s1">'{}/train.txt'</span><span class="p">.</span>format<span class="p">(</span>TXT_DIR<span class="p">),</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="k">f</span><span class="p">:</span>
    <span class="k">for</span> image <span class="k">in</span> dog_train<span class="p">:</span>
        <span class="k">f</span><span class="p">.</span>write<span class="p">(</span><span class="s1">'{} 0\n'</span><span class="p">.</span>format<span class="p">(</span>image<span class="p">))</span>
    <span class="k">for</span> image <span class="k">in</span> cat_train<span class="p">:</span>
        <span class="k">f</span><span class="p">.</span>write<span class="p">(</span><span class="s1">'{} 1\n'</span><span class="p">.</span>format<span class="p">(</span>image<span class="p">))</span>
 
with open<span class="p">(</span><span class="s1">'{}/text.txt'</span><span class="p">.</span>format<span class="p">(</span>TXT_DIR<span class="p">),</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="k">f</span><span class="p">:</span>
    <span class="k">for</span> image <span class="k">in</span> dog_test<span class="p">:</span>
        <span class="k">f</span><span class="p">.</span>write<span class="p">(</span><span class="s1">'{} 0\n'</span><span class="p">.</span>format<span class="p">(</span>image<span class="p">))</span>
    <span class="k">for</span> image <span class="k">in</span> cat_test<span class="p">:</span>
        <span class="k">f</span><span class="p">.</span>write<span class="p">(</span><span class="s1">'{} 1\n'</span><span class="p">.</span>format<span class="p">(</span>image<span class="p">))</span></code></pre></figure>

<p>Then, all you have to do is to execute the Python script you have just created above:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">python examples/DogsCatsKaggle/create_kaggle_txt.py</code></pre></figure>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>Now let’s jump into <em>./data/DogsCatsKaggle</em>, you will see <em>train.txt</em> and <em>test.txt</em> has been created. And that’s just it. We have finished creating the two mapping files for <em>Dogs vs Cats</em> dataset from Kaggle!</p>

<p>So, what about the Dogs and Cats images from ImageNet? Well, you may want to take a look at <em>./data/DogsCats</em>. Voila! When were the two files created? - You may ask. They were created when you ran the script to download the images! So with ImageNet’s dataset, you don’t have to create the mapping files yourself. That was great, right? Now we got the images, the mapping text files ready, there’s only one step left to deal with the data: create the <em>mean image</em>.</p>

<ul>
  <li>The need of computing the mean image</li>
</ul>

<p>Why do we need the mean image anyway? First, that’s just one type of <em>Data Normalization</em>, a technique to process our data before training. As I told you in previous post, the final goal of the learning process is finding the global minimum of the cost function. There’s many factors that affect the learning process, one of which is how well our data was pre-processed. The better it is pre-processed, the more likely our Model will learn faster and better.</p>

<p>The goal of computing the mean image is to make our data have zero mean. What does that mean? For example, we have a set of training data like this: \(x^{(1)}, x^{(2)}, \dots, x^{(m)}\). Let’s call \(x_\mu\) the mean value, which means:</p>

<script type="math/tex; mode=display">x_\mu=\frac{x^{(1)}+x^{(2)}+\dots+x^{(m)}}{m}=\frac{1}{m}\sum_{i=1}^mx^{(i)}</script>

<p>Next, a new set of data will be created, where each \(x_{new}^{(i)}=x^{(i)}-x_\mu\). It’s easy to see that the mean value of the new dataset is zero:</p>

<script type="math/tex; mode=display">\sum_{i=1}^mx_{new}^{(i)}=\sum_{i=1}^mx^{(i)}-mx_\mu=\sum_{i=1}^mx^{(i)}-m\frac{1}{m}\sum_{i=1}^mx^{(i)}=0</script>

<p>So, above I just showed you a short explanation about one type for Data Normalization, which subtracting by the mean value to get a new dataset with zero mean. I will talk more about Data Normalization in future post. Now, how do we compute the mean image? As you may guess, of course Caffe provides some script to deal with some particular dataset. And we’re gonna make use of it with some modifications! But before we can compute the mean image, we must convert our images into <em>LMDB</em> format first.</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds2 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="2275566366" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<ul>
  <li>Converting data into LMDB format</li>
</ul>

<p>But first, why LMDB? Why is LMDB converting considered recommended, especially when we are working with large image database? To make it short, because it helps improving the performance of our Network. At present, performance is not all about accuracy anymore, but required to be both fast and accurate. With a same Network and a same dataset, how the data was prepared will decide how fast our Network learns. And LMDB conversion is one way (among many) which helps accomplish that. And the trade-off? The converted LMDB file will double the size of your downloaded images, since your images were decompressed before being converted (that’s one reason why our Network performs faster with LMDB file, right?)</p>

<p>Next, let’s copy the necessary script that we will make use of. I will use <em>Dogs vs Cats</em> dataset from Kaggle for example.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo cp </span>examples/imagenet/create_imagenet.sh examples/DogsCatsKaggle/</code></pre></figure>

<p>To convert the downloaded <em>Dogs vs Cats</em> dataset to LMDB format using the script above, we will have to make some changes. But it’s not a big deal at all because all we have to change is just the correct path to our images and the mapping text files. Below is the lines which I have applied changes for your reference:</p>

<figure class="highlight"><pre><code class="language-vim" data-lang="vim">EXAMPLE<span class="p">=</span>examples/DogsCatsKaggle
DATA<span class="p">=</span>data/DogsCatsKaggle
TOOLS<span class="p">=</span>build/tools
 
TRAIN_DATA_ROOT<span class="p">=</span>data<span class="sr">/DogsCatsKaggle/</span>train/
VAL_DATA_ROOT<span class="p">=</span>data<span class="sr">/DogsCatsKaggle/</span>train/
<span class="p">...</span>
RESIZE<span class="p">=</span>true
<span class="p">...</span>
GLOG_logtostderr<span class="p">=</span><span class="m">1</span> $TOOLS/convert_imageset \
<span class="p">...</span>
    $EXAMPLE/dogscatskaggle_train_lmdb

echo <span class="s2">"Creating val lmdb..."</span>
 
GLOG_logtostderr<span class="p">=</span><span class="m">1</span> $TOOLS/convert_imageset \

<span class="p">...</span>
    $DATA/text<span class="p">.</span>txt \
    $EXAMPLE/dogscatskaggle_val_lmdb
 
echo <span class="s2">"Done."</span></code></pre></figure>

<p>Next, let’s go ahead and run the script above:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./examples/DogsCatsKaggle/create_imagenet.sh </code></pre></figure>

<p>It will take a while for the conversion to complete. After the process completes, take a look at <em>./examples/DogsCatsKaggle</em> folder, you will see two new folders which are named <em>dogscatskaggle_train_lmdb</em> and <em>dogscatskaggle_val_lmdb</em>, and new LMDB files were placed inside each folder, created from the training data and test data respectively.</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<ul>
  <li>Making the mean image</li>
</ul>

<p>After creating LMDB files, making the mean image is no other than one last simple task to complete. All we have to do is to copy and apply some tiny changes into the script which computes the mean image.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo cp </span>examples/imagenet/make_imagenet_mean.sh examples/DogsCatsKaggle/</code></pre></figure>

<p>And here’s what it looks after modified:</p>

<figure class="highlight"><pre><code class="language-vim" data-lang="vim">EXAMPLE<span class="p">=</span>examples/DogsCatsKaggle
DATA<span class="p">=</span>data/DogsCatsKaggle
TOOLS<span class="p">=</span>build/tools
 
$TOOLS<span class="sr">/compute_image_mean $EXAMPLE/</span>dogscatskaggle_train_lmdb \
  $DATA/dogscatskaggle_mean<span class="p">.</span>binaryproto</code></pre></figure>

<p>And, only one last command to execute:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./examples/DogsCatsKaggle/make_imagenet_mean.sh </code></pre></figure>

<p>And that’s it. Let’s go into <em>./data/DogsCatsKaggle</em> folder, you will see one new file called <em>dogscatskaggle_mean.binaryproto</em>, which means that the mean image was created successfully!</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds2 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="2275566366" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p><strong>3. Training with your prepared data</strong><br />
So now you nearly got everything ready to train the Network with the data prepared by yourself. The last thing is, of course, the Network! At this time, you may want to create a Network of your own, and train it using the data above (of your own, too!). But I recommend you try some available Networks which is provided by Caffe, some of which are very famous such as VGG16 or AlexNet. Let’s pick AlexNet for now since it’s quite simpler than VGG16, which will make it train faster. We need to create one new folder and copy the necessary files for Network definition. And for your information, Caffe uses the <em>protobuf</em> format to define the Networks, which you can read for details here: <a href="https://developers.google.com/protocol-buffers/" target="_blank">Protocol Buffers</a>.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd </span>models
mkdif dogscatskaggle_alexnet
<span class="nb">sudo cp </span>bvlc_alexnet/solver.prototxt dogscatskaggle_alexnet/
<span class="nb">sudo cp </span>bvlc_alexnet/train_val.prototxt dogscatskaggle_alexnet/</code></pre></figure>

<p>Let’s first modify the <em>solver.prototxt</em> first. This file stores the necessary information which the Network needs to know before training, such as the path to the Network definition file, the learning rate, momentum, weight decay iterations, etc. But all you need to do is just to change the file paths:</p>

<figure class="highlight"><pre><code class="language-vim" data-lang="vim">net<span class="p">:</span> <span class="s2">"models/dogscatskaggle_alexnet/train_val.prototxt"</span>
<span class="p">...</span>
snapshot_prefix<span class="p">:</span> <span class="s2">"models/dogscatskaggle_alexnet/caffe_alexnet_train"</span></code></pre></figure>

<p>Next, we will make change to the Network definition file, which is the <em>train_val.prototxt</em> file. In fact, it was nearly set up and we only need to modify a little bit. First, we have to tell it where to look for your prepared data. And second, we must change the output layer, since our dataset only contains two classes (change this accordingly if you have a different dataset with me). Now open up the file, you will see the first two layers are the data layers, which provide the input to the Network. Stanford University has an excelent tutorial on defining the Network in Caffe at here: <a href="http://vision.stanford.edu/teaching/cs231n/slides/caffe_tutorial.pdf" target="_blank">Caffe Tutorial</a>.</p>

<p>Let’s change the path to the mean image and two LMDB folders which we created above:</p>

<figure class="highlight"><pre><code class="language-vim" data-lang="vim">name<span class="p">:</span> <span class="s2">"AlexNet"</span>
layer <span class="p">{</span>
  name<span class="p">:</span> <span class="s2">"data"</span>
  type<span class="p">:</span> <span class="s2">"Data"</span>
  <span class="k">top</span><span class="p">:</span> <span class="s2">"data"</span>
  <span class="k">top</span><span class="p">:</span> <span class="s2">"label"</span>
  include <span class="p">{</span>
    phase<span class="p">:</span> TRAIN
  <span class="p">}</span>
  transform_param <span class="p">{</span>
    mirror<span class="p">:</span> true
    crop_size<span class="p">:</span> <span class="m">227</span>
    mean_file<span class="p">:</span> <span class="s2">"data/DogsCatsKaggle/dogscatskaggle_mean.binaryproto"</span> # MODIFIED
  <span class="p">}</span>
  data_param <span class="p">{</span>
    source<span class="p">:</span> <span class="s2">"examples/DogsCatsKaggle/dogscatskaggle_train_lmdb"</span> # MODIFIED
    batch_size<span class="p">:</span> <span class="m">256</span>
    backend<span class="p">:</span> LMDB
  <span class="p">}</span>
<span class="p">}</span>
layer <span class="p">{</span>
  name<span class="p">:</span> <span class="s2">"data"</span>
  type<span class="p">:</span> <span class="s2">"Data"</span>
  <span class="k">top</span><span class="p">:</span> <span class="s2">"data"</span>
  <span class="k">top</span><span class="p">:</span> <span class="s2">"label"</span>
  include <span class="p">{</span>
    phase<span class="p">:</span> TEST
  <span class="p">}</span>
  transform_param <span class="p">{</span>
    mirror<span class="p">:</span> false
    crop_size<span class="p">:</span> <span class="m">227</span> 
    mean_file<span class="p">:</span> <span class="s2">"data/DogsCatsKaggle/dogscatskaggle_mean.binaryproto"</span> # MODIFIED
  <span class="p">}</span>
  data_param <span class="p">{</span>
    source<span class="p">:</span> <span class="s2">"examples/DogsCatsKaggle/dogscatskaggle_val_lmdb"</span> # MODIFIED
    batch_size<span class="p">:</span> <span class="m">50</span>
    backend<span class="p">:</span> LMDB
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>And there’s only one place left to change: the output layer. Let’s look through the file to find the layer named <em>fc8</em>, that’s the last layer of our Network. It now has 1000 outputs because it was created to train on full ImageNet’s images. Let’s change the number of output according to our dataset:</p>

<figure class="highlight"><pre><code class="language-vim" data-lang="vim">layer <span class="p">{</span>
  name<span class="p">:</span> <span class="s2">"fc8"</span>
<span class="p">...</span>
  inner_product_param <span class="p">{</span>
    num_output<span class="p">:</span> <span class="m">2</span> # MODIFIED
<span class="p">...</span>
<span class="p">}</span></code></pre></figure>

<p>Then save the file and that’s it, you can now train the Network with your own dataset! We can’t wait to do it, can we?</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">./build/tools/caffe train <span class="nt">--solver</span><span class="o">=</span>models/dogscatskaggle_alexnet/solver.prototxt</code></pre></figure>

<p>Our Network should be running flawlessly now. And all we have to do is wait until it’s done! We have come a long way until this point. So I think we deserve a cup of coffee or something. That was so fantastic! You all did a great job today.</p>

<h3 id="summary">Summary</h3>

<p>So in today’s post, I have shown you how to train the Network in Caffe, using your own dataset. We went through from how to download the data from URLs file (or directly from host), how to prepare the data to be read by the Network and how to make change to the Network to make it work using our dataset. As you could see, it was not so hard, but it did require some time to dig into. I hope this post can save you quite some of your previous times, and instead, you can spend them on improving your Network’s performance. And that’s all for today. Thank you for reading such a long post. And I’m gonna see you again in the coming post!</p>


    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <!-- New Ads -->
    <ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3852793730107162"
     data-ad-slot="4068904466"
     data-ad-format="auto"></ins>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
    
    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/mahaveer0suthar"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/mahaveer0suthar.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Mahaveer Suthar. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
      </footer>
    </div>

    <script src="http://localhost:4000/mahaveer0suthar.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-137799718-1', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>
