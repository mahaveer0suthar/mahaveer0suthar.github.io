

<!doctype html>
<html lang="en" class="no-js">
  <head>
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-3852793730107162",
        enable_page_level_ads: true
      });
    </script>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Real Time Object Recognition (Part 2) - Mahaveer Senior Deep Learning Engineer</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Mahaveer Senior Deep Learning Engineer">
<meta property="og:title" content="Real Time Object Recognition (Part 2)">


  <link rel="canonical" href="http://localhost:4000/mahaveer0suthar.github.io/project/Real-Time-Object-Recognition-part-two/">
  <meta property="og:url" content="http://localhost:4000/mahaveer0suthar.github.io/project/Real-Time-Object-Recognition-part-two/">



  <meta property="og:description" content="So here we are again, in the second part of my Real time Object Recognition project. In the previous post, I showed you how to implement pre-trained VGG16 model, and have it recognize my testing images.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2017-09-30T00:00:00+05:30">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Mahaveer Suthar",
      "url" : "http://localhost:4000/mahaveer0suthar.github.io",
      "sameAs" : null
    }
  </script>



  <meta name="google-site-verification" content="ho8trrB9Qh7KHvxD-AUywATdPAOr6EJQ3pQbX6bfZFA" />




<!-- end SEO -->


<link href="http://localhost:4000/mahaveer0suthar.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Mahaveer Senior Deep Learning Engineer Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/mahaveer0suthar.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">


    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--post">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/mahaveer0suthar.github.io/">Mahaveer Senior Deep Learning Engineer</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/mahaveer0suthar.github.io/about/">About</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://mahaveer0suthar.github.io/portfolio/">Projects</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/mahaveer0suthar.github.io/experience/">Professional Experience</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/mahaveer0suthar.github.io/skills/">Skills & Areas of Interests</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/mahaveer0suthar.github.io/education/">Education</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://mahaveer0suthar.github.io/tutorials/">Tutorials</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <p>So here we are again, in the second part of my Real time Object Recognition project. In the previous post, I showed you how to implement pre-trained VGG16 model, and have it recognize my testing images.</p>

<p>You can take a look at the first part here: <a href="https://mahaveer0suthar.github.io/project/Real-Time-Object-Recognition-part-one/" target="_blank">Real Time Object Recognition (Part 1)</a>.
The model performed pretty well, although I didn’t even have to do any further pre-processing (such as object localization, or image enhancement, etc).</p>

<p>In the next step, I will use the same model, to predict object from a continuous input, such as video file or input from a camera. If you have ever done some work with Computer Vision before, you will see find it extremely easy. Let’s say, just a slight improvement over the last one. Yeah, that’s true!</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>For ones who have no experience in Computer Vision, I’ll explain a little bit here. So, if you have an image, and want to have it recognized. Here is what you do:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Load the image
</span>
<span class="c1"># Use the model to have the image recognized
</span>
<span class="c1"># Show the result</span></code></pre></figure>

<p>Now, you have a video file, how to make it work? You know that movies, videos are just hundreds or thousands of images shown continuously. So what you have to do, is just read through a video, from its first image, to the last one. And you see that it works exactly the same way with the one above.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Load the video
</span><span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">video</span><span class="p">:</span>
  <span class="c1"># Use the model to have the image recognized
</span>  <span class="c1"># Show the result</span></code></pre></figure>

<p>Easy, right? As shown above, the result is shown continuously to your eyes. And your eyes will treat them as a video, not seperate  images.</p>

<p>Here comes something to consider about. Remember the conflict between OpenCV and Keras that I mentioned in the last post? To recall a little bit, After reading the input image, OpenCV and Keras turn it into arrays in different ways. So basically, if we want the model to recognize the input image, we have two choices to pick.</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds2 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="2275566366" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>Use the Keras’ method:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span> <span class="k">as</span> <span class="n">image_utils</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">image_utils</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">image_utils</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span></code></pre></figure>

<p>Or, use the OpenCV’s method, then converting to Keras’ format:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span></code></pre></figure>

<p>As you can see, Keras’ method reads the image from file, then performs conversion. In case of reading from a camera, it may be a little bit odd to read each frame, then immediately save to disk, then have it read by Keras. Doing like so will slow down the performance, and it is obviously not an efficient solution.</p>

<p>Remember I said that I prefered the approach which using OpenCV’s method? Because I just needed to perform one matrix transpose, and I had everything ready for Keras, without saving and reading from disk anymore.</p>

<p>So, by just adding two lines of code made things done. Why the hell must I split it into two parts? Well, because there’s a tiny problem in performance. Obviously, everyone does prefer a perfect show, right?</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>What’s the problem then? I told you in the first part, that our model is quite a big guy (it can distinguish between 1000 classes). Big guys tend to move slowly, so does the VGG16 model. It took approximately 1.5 ~ 2 seconds to recognize ONE image (on my PC). So what will it be like when dealing with an input from a camera (or a video file)? Definitely, it will be a very horrible scene that you never wish to see.</p>

<p>Therefore, we come to a fact that we must do something here, or we are likely to ruin the show. There may be many tricks out there, I think. But in my case, I just simply, put the recognition task in another thread. Whenever the recognition on a frame is ready to deliver, I updated the result. On the other side, the output was smoothly shown since it no longer had to wait for the recognition result.</p>

<p>Ones with little experience in programming, especially multi-threading, would find what I said hard to understand. Don’t worry, I’ll explain right below:</p>

<p>In case of no multi-threading:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Load the video
</span><span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">video</span><span class="p">:</span>
  <span class="c1"># Use the model to have the image recognized
</span>  
  <span class="c1"># 2 SECONDS LATER...
</span>  
  <span class="c1"># Show the result</span></code></pre></figure>

<p>With multi-threading:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Load the video
</span><span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">video</span><span class="p">:</span>
  <span class="c1"># Show the image with the last result put on it
</span>
<span class="c1"># Somewhere else on Earth
</span>  <span class="c1"># Load the image to recognize
</span>  
  <span class="c1"># Perform recognition
</span>  
  <span class="c1"># 2 SECONDS LATER...
</span>  
  <span class="c1"># Output the result</span></code></pre></figure>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds2 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="2275566366" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>Do you get the trick here? When implementing multi-threading, the codes which deal with recognition task is seperated from the output task. It will return the result each 2 seconds. On the other side, because the output won’t have to wait for the recognition result, it just simply puts the last received result on, and updates when the new one is delivered.</p>

<p>You make ask, so the recognition process is actually skipping everything between the 2-second periods, so what we see in the output may not be the exact result. For example, your camera was on a dog, and you passed the frame containing the dog to the recognition code, 2 seconds later, the Dog label was delivered, but you are now looking at a lion! What a shame on a real time recognition app! Well, it sounds like an interesting theory. But I think, no one moves their cameras that fast, let’s say, abruptly change the view each second. Am I right?</p>

<p>So, you now know about the problem you may face working with real time object recognition, and I showed you how to deal with it by implementing multi-threading. But…
If there’s something I need you to know about me, it’s that I am not a professional programmer, which means I prefer working on theoretical algorithms to spending hours on coding. To me, coding is simply a way to visualize the theory. Therefore, my code may seem like a mess to you guys. So feel free to tell me if you find something wrong or something which can be improved. I will definitely appreciate that.</p>

<p>Tired of reading? So sorry to make it long. I’ll show you the result I got right below:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/70Kv8Rr72ag" frameborder="0" allowfullscreen></iframe>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="4068904466" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>Let’s talk a little bit about the result above. You can see that, despite of the bad light condition (my room is only equipped with one damn yellow light!), the model still performed pretty well and totally satisfied me. Sometimes it got wrong (couldn’t recognize my G-Shock, or having trouble in distinguishing whether it was a screen or a TV!), but that was far more than expected.</p>

<p>And finally, here’s the code in case you need: <a href="https://github.com/mahaveer0suthar/DeepLearning" target="_blank">Object Recognition Code</a>. Most of them was cloned from François Chollet’s repository. I just coded two files below:</p>

<ul>
  <li>
    <p>For recognizing images seperately:
test_imagenet.py</p>
  </li>
  <li>
    <p>For real time object recognition with camera:
camera_test.py</p>
  </li>
</ul>

<p>Hope you enjoy this project. Feel free to leave me some feedbacks or questions. I will be more than pleased to help.</p>

<script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- MidPageAds2 -->
<p><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3852793730107162" data-ad-slot="2275566366" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>So we are done with this Real time Object Recognition project, but not with Machine Learning! And I’ll see you soon, in the next projects!</p>


    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <!-- New Ads -->
    <ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-3852793730107162"
     data-ad-slot="4068904466"
     data-ad-format="auto"></ins>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
    
    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/mahaveer0suthar"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/mahaveer0suthar.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2020 Mahaveer Suthar. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>
      </footer>
    </div>

    <script src="http://localhost:4000/mahaveer0suthar.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-137799718-1', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>
